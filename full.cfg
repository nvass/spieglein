# list of jobs that will be executed
active="backupserver www ftp localbackupserver"

# setting inparallel to an non-empty string will execute all jobs in parallel
inparallel=

# lock each job with the following command. FreeBSD example:
lockf=lockf
lockf_params="-t 10 /tmp/\$job /bin/sh \$backup_function_params"

# lock each job with the following command. Linux example:
#lockf=flock
#lockf_params="-w 10 /tmp/\$job /bin/sh \$backup_function_params"

# setting verbose to an non-empty string will print more messages
#verbose=

# filter snapshots. Without a filter the latest snapshot is always copied
#filter=egrep
#filter_params="_(06|12|18)-30-"

# Without -u datasets might mount on the backup server.
# Normally you *never* want to change this default.
# Never forget to add it when overriding recv_params.
# Incoming backed up filesystems might mask your local filesystems.
recv_params=-u

# set compression globally
compress=xz
decompress=unxz

# set ssh_user globally
ssh_user=backup

# export all globals that we need
#export filter filter_params
export ssh_user
export compress compress_params
export decompress decompress_params

# Job definitions. Variables in job definitions will be evaluated and mask global values.
# Setting a value to an empty string e.g. compress= can be used to effectively delete a global value
backupserver='
filter=grep
filter_params="_06-30-"
ssh_host=backupserver.somedomain.tld
ssh_params="-o port=3333"
ssh_user=backup
datasets="clio|backup/clio storage|backup/storage"
'

www='
ssh_host=www.somedomain.tld
ssh_user=backup
datasets="pool/backups|backup/www"
'

ftp='
ssh_host=ftp.somedomain.tld
ssh_user=backup
datasets="ftp|backup/ftp"
'

# override compression and override ssh_user
# copy pool/backups to backup/localbackupserver/backups
localbackupserver='
compress=
ssh_host=10.32.0.10
ssh_user=paul
datasets="pool/backups|backup/localbackupserver/backups"
'

# copy castor and pollux to dedicated pools with same names"
example1='
ssh_host=10.32.0.11
ssh_user=testuser
datasets="castor|castor pollux|pollux"
'

# copy only var usr home without recursing into children datasets
# copy last snapshot that matches "fgrep _BACKUP_"
# override global "zfs send" with -v
example2='
send_params=-v
filter=fgrep
filter_params="_BACKUP_"
ssh_host=10.32.0.12
ssh_user=testuser
norecursion=1
datasets="zeus/root/var|zeus/var zeus/root/usr|zeus/usr zeus/root/home|zeus/home"
'
